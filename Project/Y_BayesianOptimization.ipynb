{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abitha09062002/Seizure_Detection_Hyperparameter/blob/main/Project/Y_BayesianOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSrvtynS3jRs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "   from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJIkxyQCLXGc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras as ke\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection  import train_test_split\n",
        "from sklearn.model_selection  import cross_val_score\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "#from bayes_opt import BayesianOptimization\n",
        "import BayesianOptimization\n",
        "#import bayes_opt.BayesianOptimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import LeakyReLU\n",
        "LeakyReLU = LeakyReLU(alpha=0.1)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQp6h-Om3a8_",
        "outputId": "a608edd8-f3d2-4f28-d730-ad8b0a251e49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       0    1    2    3    4    5    6    7    8    9    10   11   12   13   \\\n",
            "0      135  190  229  223  192  125   55   -9  -33  -38  -10   35   64  113   \n",
            "1      386  382  356  331  320  315  307  272  244  232  237  258  212    2   \n",
            "2      -32  -39  -47  -37  -32  -36  -57  -73  -85  -94  -99  -94  -96 -104   \n",
            "3     -105 -101  -96  -92  -89  -95 -102 -100  -87  -79  -72  -68  -74  -80   \n",
            "4       -9  -65  -98 -102  -78  -48  -16    0  -21  -59  -90 -103  -84  -43   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495  -22  -22  -23  -26  -36  -42  -45  -42  -45  -49  -57  -64  -73  -79   \n",
            "11496  -47  -11   28   77  141  211  246  240  193  136   78    8  -66 -132   \n",
            "11497   14    6  -13  -16   10   26   27   -9    4   14   -1  -10   14   44   \n",
            "11498  -40  -25   -9  -12   -2   12    7   19   22   29   22    6    1  -28   \n",
            "11499   29   41   57   72   74   62   54   43   31   23   13   11   -3   -5   \n",
            "\n",
            "       14   15   16    17    18    19   20   21   22   23   24   25   26   \\\n",
            "0      152  164  127    50   -47  -121 -138 -125 -101  -50   11   39   24   \n",
            "1     -267 -605 -850 -1001 -1109 -1090 -967 -746 -464 -152  118  318  427   \n",
            "2     -103  -92  -75   -69   -69   -53  -37  -14  -10  -39  -78 -102  -98   \n",
            "3      -83  -73  -68   -61   -58   -59  -64  -79  -84  -97  -94  -84  -77   \n",
            "4       -9    3  -21   -60   -96  -103  -75  -29   14   55   78   73   28   \n",
            "...    ...  ...  ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495  -76  -70  -63   -57   -57   -50  -45  -34  -33  -32  -30  -24  -24   \n",
            "11496 -180 -210 -227  -225  -212  -192 -168 -144 -117  -88  -54  -21    6   \n",
            "11497   77   61   42    32    29    22   26   35   81   66   50   57   91   \n",
            "11498  -37  -35  -35   -45   -64  -105 -140 -157 -157 -147 -153 -147 -126   \n",
            "11499   -9  -14    1    27    60    69   69   50   33   20   15    4   -5   \n",
            "\n",
            "       27   28   29   30   31   32   33   34   35   36   37   38   39   40   \\\n",
            "0       48   64   46   13  -19  -61  -96 -130 -132 -116 -115  -71  -14   25   \n",
            "1      473  485  447  397  339  312  314  326  335  332  324  310  312  309   \n",
            "2      -80  -54  -40  -35  -39  -32  -13    7   34   41   33    6  -15  -30   \n",
            "3      -75  -72  -68  -76  -76  -72  -67  -69  -69  -69  -67  -68  -69  -67   \n",
            "4      -13  -43  -68  -78  -75  -55  -41  -19  -20  -29  -36  -20    1   16   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495  -18   -9   -2    0    2   -3   -5  -13  -23  -39  -53  -59  -63  -63   \n",
            "11496   29   46   60   76   92  110  128  152  171  150   91   21  -29  -52   \n",
            "11497  121  111   73   38   23   35   21   11  -12    2   17   61   88   90   \n",
            "11498 -112  -83  -56  -41  -40  -38  -34  -47  -41  -40  -42  -49  -56  -77   \n",
            "11499   -4   -8  -15  -13   -2   21   39   48   37   10  -23  -47  -71  -80   \n",
            "\n",
            "       41   42   43   44   45   46   47   48   49   50   51   52   53   54   \\\n",
            "0       19    6    9   21   13  -37  -58  -33    5   47   80  101   88   73   \n",
            "1      309  303  297  295  295  293  286  279  283  301  308  285  252  215   \n",
            "2      -47  -53  -65  -64  -68  -85  -98 -109  -82  -57  -38  -40  -36  -31   \n",
            "3      -66  -58  -54  -56  -70  -80  -82  -85  -74  -70  -71  -82  -88  -93   \n",
            "4       14  -14  -42  -56  -45  -45  -45  -38  -47  -45  -37   -3   23   39   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495  -60  -57  -52  -46  -33  -27  -33  -32  -29  -27  -22  -18  -11  -13   \n",
            "11496  -67  -96 -123 -143 -155 -167 -176 -185 -185 -171 -132  -75  -17   36   \n",
            "11497   76   18    5   10   23   48   32    4  -35  -23   -7   25   20    6   \n",
            "11498 -105 -110 -103  -89  -80  -81  -98 -113 -124 -106  -85  -59  -30  -14   \n",
            "11499  -74  -59  -44  -30  -17   -3    6   13   20   22   20   14  -15  -38   \n",
            "\n",
            "       55   56   57   58   59   60   61   62   63    64    65   66   67   68   \\\n",
            "0       69   41  -13  -31  -61  -80  -77  -66  -43     5    87  129  121   88   \n",
            "1      194  169  111  -74 -388 -679 -892 -949 -972 -1001 -1006 -949 -847 -668   \n",
            "2      -13   11   19    9  -20  -48  -71  -71  -57   -32   -13    6   29   27   \n",
            "3      -97  -89  -87  -83  -70  -50  -37  -31  -32   -39   -54  -64  -68  -67   \n",
            "4       27    0  -28  -44  -37  -22    5   30   31     6   -32  -27  -27    2   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...  ...  ...  ...   \n",
            "11495  -12  -17  -23  -28  -24  -16  -14  -10   -6    -3     5   15   29   38   \n",
            "11496   73   95  108  119  128  125  120  113  110   107   106  108  104   88   \n",
            "11497    0   30   33   17  -18  -36   -6    5   26    10    -9   -1   15   47   \n",
            "11498   -3   -1    8   19   21   29   25   28   25    27    21    5   -9  -18   \n",
            "11499  -53  -62  -69  -77  -75  -85  -87  -76  -66   -59   -42  -29  -19  -19   \n",
            "\n",
            "       69   70   71   72   73   74   75   76   77   78   79   80   81   82   \\\n",
            "0       12  -76 -150 -207 -186 -165 -148 -103  -33   40   94   75    8  -81   \n",
            "1     -432 -153   72  226  326  392  461  495  513  511  496  479  453  440   \n",
            "2       25   10   -7  -36  -47  -37  -36  -22  -32  -38  -55  -61  -64  -72   \n",
            "3      -69  -63  -60  -63  -55  -43  -37  -27  -31  -35  -47  -58  -63  -74   \n",
            "4       13   -6  -29  -41  -22  -13  -16  -31  -52  -60  -40  -16    0   14   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495   44   48   46   50   63   69   73   70   58   51   41   30   11    9   \n",
            "11496   45  -30 -137 -205 -219 -175 -110  -77  -69  -72  -79  -75  -72  -59   \n",
            "11497   74   53   17  -20  -42  -41  -49  -41    2   12   17    8    9   59   \n",
            "11498  -40  -53  -70  -77  -94  -77  -68  -39   -1   12   12    6   11   10   \n",
            "11499  -27  -37  -39  -26   -7   -5  -18  -36  -54  -66  -52  -37   -6   20   \n",
            "\n",
            "       83   84   85   86   87   88   89   90   91   92   93   94   95   96   \\\n",
            "0     -155 -227 -262 -233 -218 -187 -126  -65  -12   27   61   49    9  -46   \n",
            "1      427  414  399  385  385  404  432  444  437  418  392  373  363  365   \n",
            "2      -67  -53  -25  -10   -4  -23  -55  -93 -102 -106 -101  -69  -45  -42   \n",
            "3      -73  -67  -60  -56  -49  -46  -57  -58  -62  -63  -63  -61  -56  -65   \n",
            "4       24   36   39   34   17   -7  -14   -1   16   27   28   18   -2   -8   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495    0    0  -11  -21  -12  -11   -1    4    6   11   20   34   40   51   \n",
            "11496  -39  -18    1    9   21   26   35   46   57   69   86  103  121  134   \n",
            "11497   47   35   -9  -53  -53  -44  -29  -18  -12   15   67   83   82   34   \n",
            "11498    0  -24  -35  -57  -66  -81 -112 -123 -149 -156 -137 -107  -57  -38   \n",
            "11499   47   47   37   27   19   17   12    8  -11  -34  -31  -19    4   27   \n",
            "\n",
            "       97   98   99   100  101  102  103  104  105  106  107  108  109  110  \\\n",
            "0     -124 -210 -281 -265 -181  -89   -4   53   53   38   43   31   34    9   \n",
            "1      372  385  388  383  371  360  353  334  303  252  200  153  151  143   \n",
            "2      -57  -64  -77  -80  -77  -78  -56  -34   -5   10    5   -5  -44  -75   \n",
            "3      -62  -57  -61  -63  -66  -69  -86  -89  -86  -83  -87  -80  -69  -62   \n",
            "4        9   27   23   21   10   15   22   41   49   55   57   46   37   31   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495   57   58   56   61   64   66   63   58   56   48   45   38   30   25   \n",
            "11496  145  151  165  190  219  247  244  216  155   68  -40 -177 -309 -388   \n",
            "11497   13    2    9   -3    3   30   61   89  115   92   70   34   33   48   \n",
            "11498  -33  -30  -36  -39  -37  -45  -37  -38  -31  -33  -43  -46  -61  -66   \n",
            "11499   66   94  110  107   93   84   83   94   65   17  -38  -65  -61  -36   \n",
            "\n",
            "       111  112  113  114   115   116  117  118  119  120  121  122  123  124  \\\n",
            "0       -7  -34  -70  -84  -101   -70  -11   42   62   66   74   64   59   56   \n",
            "1       48 -206 -548 -859 -1067 -1069 -957 -780 -597 -460 -357 -276 -224 -210   \n",
            "2      -99 -110 -104 -103   -94  -105 -108 -110  -99  -89  -82  -76  -80  -90   \n",
            "3      -57  -60  -60  -68   -58   -53  -57  -66  -66  -73  -78  -73  -84  -92   \n",
            "4       40   38   35   30     3   -34  -51  -42  -23   -1   23   35   35   17   \n",
            "...    ...  ...  ...  ...   ...   ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495   22   22   26   31    32    37   38   46   53   54   57   51   47   39   \n",
            "11496 -377 -295 -186 -100   -48   -26  -16    0    7   16   23   33   41   42   \n",
            "11497   39   39   37   43    50    56   29   31   47   48   49   22   11   -2   \n",
            "11498  -71  -52  -28  -22   -16     0    6    4   11   14   11   17   17   13   \n",
            "11499   -2    9   25   38    56    70   70   58   27   -1  -12  -24  -50  -73   \n",
            "\n",
            "       125  126   127   128   129  130  131  132  133  134  135  136  137  \\\n",
            "0       36  -11   -30   -43   -23    8   42   77  103  135  121   79   59   \n",
            "1     -350 -930 -1413 -1716 -1360 -662  -96  243  323  241   29 -167 -228   \n",
            "2     -106 -106  -108   -87   -60  -37  -26  -15   -6  -14  -23  -34  -41   \n",
            "3      -97  -88   -81   -72   -61  -66  -72  -88  -90  -88  -77  -58  -53   \n",
            "4       -1  -17    -8    26    55   54   38   19    4   -1   10   22   26   \n",
            "...    ...  ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495   38   26     9     0    -9  -15  -19  -20  -18  -14    0    9   21   \n",
            "11496   45   44    47    48    52   57   61   60   54   53   55   62   65   \n",
            "11497   -8   15    -1   -20   -43  -48  -44  -22  -17   18   50   45   -9   \n",
            "11498   -5  -21   -53   -79   -98 -103  -99  -81  -56  -61  -67 -111 -112   \n",
            "11499  -80  -70   -37     7    49   65   64   44   15  -14  -38  -68  -99   \n",
            "\n",
            "       138  139  140  141  142  143  144  145  146  147  148  149  150  151  \\\n",
            "0       43   54   90  111  107   64   32   18  -25  -69  -65  -44  -33  -57   \n",
            "1     -136   27  146  229  269  297  307  303  305  306  307  280  231  159   \n",
            "2      -54  -82 -107 -126 -124 -108  -84  -68  -61  -56  -63  -62  -33    1   \n",
            "3      -61  -69  -66  -74  -69  -61  -51  -45  -45  -49  -58  -64  -78  -80   \n",
            "4       37   38   26   10   -4  -13   -8    0   10   19   29   57   63   45   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495   34   45   55   60   69   68   58   54   44   40   38   39   39   32   \n",
            "11496   68   69   58   38   16   25   75  165  260  343  406  456  471  461   \n",
            "11497  -78  -90  -62  -38  -40  -21  -23  -11   -4   -9  -22  -42  -49  -48   \n",
            "11498 -120  -98  -77  -60  -73  -88  -97 -118 -108 -100  -97  -91 -109 -122   \n",
            "11499 -107 -108  -83  -46    0   30   39   44   33   22    8  -13  -33  -61   \n",
            "\n",
            "       152  153  154  155  156  157  158  159  160  161  162  163  164  165  \\\n",
            "0      -88 -114 -130 -114  -83  -53  -79  -72  -85 -109  -98  -72  -65  -63   \n",
            "1       85   51   43   62   63   63   69   89  123  136  127  102   95  105   \n",
            "2       28   45   37   48   62   80   66   23  -11  -39  -44  -42  -45  -48   \n",
            "3      -90  -87  -83  -78  -64  -38  -22  -29  -42  -51  -68  -71  -69  -69   \n",
            "4        7  -13  -23   -9    9   11    3   -1   -2    4   18   27   27   14   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "11495   23   22   14   13   15   18   20   20   25   28   29   29   29   26   \n",
            "11496  412  319  175   -5 -171 -293 -357 -378 -370 -346 -316 -278 -241 -201   \n",
            "11497  -40  -40  -46  -43  -67  -67  -50  -18  -14  -39  -74  -86  -75  -68   \n",
            "11498 -134 -137 -107  -95  -67  -54  -40  -31  -19    7   22   46   68   87   \n",
            "11499  -70  -75  -74  -58  -18   19   54   71   76   74   65   56   18  -28   \n",
            "\n",
            "       166  167  168  169  170  171  172  173  174  175  176  177  178  \n",
            "0      -11   10    8  -17  -15  -31  -77 -103 -127 -116  -83  -51    0  \n",
            "1      131  163  168  164  150  146  152  157  156  154  143  129    1  \n",
            "2      -42   -6   29   57   64   48   19  -12  -30  -35  -35  -36    0  \n",
            "3      -74  -74  -80  -82  -81  -80  -77  -85  -77  -72  -69  -65    0  \n",
            "4       15   11   10    4    2  -12  -32  -41  -65  -83  -89  -73    0  \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
            "11495   24   24   20   15   16   12    5   -1  -18  -37  -47  -48    0  \n",
            "11496 -162 -126  -94  -65  -33   -7   14   27   48   77  117  170    1  \n",
            "11497  -57  -78  -42  -65  -48  -61  -62  -67  -30   -2   -1   -8    0  \n",
            "11498   97  105  114  121  135  148  143  116   86   68   59   55    0  \n",
            "11499  -75  -98  -94  -59  -25   -4    2    5    4   -2    2   20    0  \n",
            "\n",
            "[11500 rows x 179 columns]\n"
          ]
        }
      ],
      "source": [
        "d1=pd.read_csv('/content/gdrive/MyDrive/dataset-org.csv',header=None)\n",
        "print(d1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1tk1LCANvdx"
      },
      "outputs": [],
      "source": [
        "score_acc = make_scorer(accuracy_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crokKM-wN6KR"
      },
      "outputs": [],
      "source": [
        "X=pd.DataFrame(d1.iloc[:,:-1].values)\n",
        "Y=d1.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyQS4YRV5cJE"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state = 0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-c3u2BTwPOb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-WvJmxR5y2-"
      },
      "outputs": [],
      "source": [
        "def nn_cl_bo(neurons, activation, optimizer, learning_rate, batch_size, epochs ):\n",
        "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
        "    optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate), 'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate), 'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate), 'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
        "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', 'LeakyReLU','relu']\n",
        "    neurons = round(neurons)\n",
        "    activation = activationL[round(activation)]\n",
        "    batch_size = round(batch_size)\n",
        "    epochs = round(epochs)\n",
        "    def nn_cl_fun():\n",
        "        opt = Adam(lr = learning_rate)\n",
        "        nn = Sequential()\n",
        "        nn.add(Dense(neurons, input_dim=178, activation=activation))\n",
        "        nn.add(Dense(neurons, activation=activation))\n",
        "        nn.add(Dense(1, activation='sigmoid'))\n",
        "        nn.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "        return nn\n",
        "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
        "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "    score = cross_val_score(nn, X_train, Y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBnuCc7QGshw",
        "outputId": "2526ab74-1549-4773-9fb3-0e7588706c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | activa... | batch_... |  epochs   | learni... |  neurons  | optimizer |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7992  \u001b[0m | \u001b[0m 5.51    \u001b[0m | \u001b[0m 335.3   \u001b[0m | \u001b[0m 54.88   \u001b[0m | \u001b[0m 0.7716  \u001b[0m | \u001b[0m 36.58   \u001b[0m | \u001b[0m 1.044   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 0.2023  \u001b[0m | \u001b[0m 536.2   \u001b[0m | \u001b[0m 39.09   \u001b[0m | \u001b[0m 0.3443  \u001b[0m | \u001b[0m 99.16   \u001b[0m | \u001b[0m 1.664   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 0.7307  \u001b[0m | \u001b[0m 735.7   \u001b[0m | \u001b[0m 69.7    \u001b[0m | \u001b[0m 0.2815  \u001b[0m | \u001b[0m 51.96   \u001b[0m | \u001b[0m 0.8286  \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6791  \u001b[0m | \u001b[0m 0.6656  \u001b[0m | \u001b[0m 920.6   \u001b[0m | \u001b[0m 83.52   \u001b[0m | \u001b[0m 0.8422  \u001b[0m | \u001b[0m 83.37   \u001b[0m | \u001b[0m 6.937   \u001b[0m |\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8064  \u001b[0m | \u001b[95m 5.195   \u001b[0m | \u001b[95m 851.0   \u001b[0m | \u001b[95m 53.71   \u001b[0m | \u001b[95m 0.03717 \u001b[0m | \u001b[95m 50.87   \u001b[0m | \u001b[95m 0.7373  \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 7.355   \u001b[0m | \u001b[0m 758.2   \u001b[0m | \u001b[0m 65.22   \u001b[0m | \u001b[0m 0.2815  \u001b[0m | \u001b[0m 99.86   \u001b[0m | \u001b[0m 0.9663  \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 5.539   \u001b[0m | \u001b[0m 588.0   \u001b[0m | \u001b[0m 52.4    \u001b[0m | \u001b[0m 0.7306  \u001b[0m | \u001b[0m 39.05   \u001b[0m | \u001b[0m 2.804   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 2.871   \u001b[0m | \u001b[0m 957.8   \u001b[0m | \u001b[0m 93.5    \u001b[0m | \u001b[0m 0.8157  \u001b[0m | \u001b[0m 13.07   \u001b[0m | \u001b[0m 6.604   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7986  \u001b[0m | \u001b[0m 8.554   \u001b[0m | \u001b[0m 845.3   \u001b[0m | \u001b[0m 58.5    \u001b[0m | \u001b[0m 0.9671  \u001b[0m | \u001b[0m 47.53   \u001b[0m | \u001b[0m 2.232   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.798   \u001b[0m | \u001b[0m 0.148   \u001b[0m | \u001b[0m 230.5   \u001b[0m | \u001b[0m 24.25   \u001b[0m | \u001b[0m 0.1367  \u001b[0m | \u001b[0m 13.0    \u001b[0m | \u001b[0m 1.585   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7986  \u001b[0m | \u001b[0m 4.895   \u001b[0m | \u001b[0m 342.9   \u001b[0m | \u001b[0m 34.35   \u001b[0m | \u001b[0m 0.1581  \u001b[0m | \u001b[0m 71.47   \u001b[0m | \u001b[0m 3.283   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 6.914   \u001b[0m | \u001b[0m 735.1   \u001b[0m | \u001b[0m 55.3    \u001b[0m | \u001b[0m 0.5993  \u001b[0m | \u001b[0m 51.55   \u001b[0m | \u001b[0m 6.743   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5598  \u001b[0m | \u001b[0m 1.33    \u001b[0m | \u001b[0m 925.5   \u001b[0m | \u001b[0m 59.83   \u001b[0m | \u001b[0m 0.5966  \u001b[0m | \u001b[0m 71.62   \u001b[0m | \u001b[0m 1.242   \u001b[0m |\n",
            "| \u001b[95m 14      \u001b[0m | \u001b[95m 0.9052  \u001b[0m | \u001b[95m 7.782   \u001b[0m | \u001b[95m 585.7   \u001b[0m | \u001b[95m 25.55   \u001b[0m | \u001b[95m 0.3711  \u001b[0m | \u001b[95m 42.54   \u001b[0m | \u001b[95m 3.304   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7983  \u001b[0m | \u001b[0m 1.615   \u001b[0m | \u001b[0m 340.2   \u001b[0m | \u001b[0m 95.93   \u001b[0m | \u001b[0m 0.6591  \u001b[0m | \u001b[0m 22.15   \u001b[0m | \u001b[0m 6.495   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8452  \u001b[0m | \u001b[0m 7.576   \u001b[0m | \u001b[0m 242.2   \u001b[0m | \u001b[0m 36.29   \u001b[0m | \u001b[0m 0.8738  \u001b[0m | \u001b[0m 70.65   \u001b[0m | \u001b[0m 2.081   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 6.61    \u001b[0m | \u001b[0m 694.7   \u001b[0m | \u001b[0m 36.84   \u001b[0m | \u001b[0m 0.804   \u001b[0m | \u001b[0m 15.32   \u001b[0m | \u001b[0m 2.158   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7984  \u001b[0m | \u001b[0m 1.866   \u001b[0m | \u001b[0m 977.8   \u001b[0m | \u001b[0m 92.75   \u001b[0m | \u001b[0m 0.6797  \u001b[0m | \u001b[0m 20.37   \u001b[0m | \u001b[0m 6.706   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 0.8254  \u001b[0m | \u001b[0m 703.8   \u001b[0m | \u001b[0m 92.23   \u001b[0m | \u001b[0m 0.3464  \u001b[0m | \u001b[0m 68.75   \u001b[0m | \u001b[0m 6.476   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7296  \u001b[0m | \u001b[0m 3.366   \u001b[0m | \u001b[0m 817.1   \u001b[0m | \u001b[0m 91.69   \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 23.6    \u001b[0m | \u001b[0m 2.624   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 5.723   \u001b[0m | \u001b[0m 567.3   \u001b[0m | \u001b[0m 62.58   \u001b[0m | \u001b[0m 0.3588  \u001b[0m | \u001b[0m 69.39   \u001b[0m | \u001b[0m 3.336   \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7882  \u001b[0m | \u001b[0m 4.091   \u001b[0m | \u001b[0m 299.8   \u001b[0m | \u001b[0m 53.0    \u001b[0m | \u001b[0m 0.2804  \u001b[0m | \u001b[0m 41.21   \u001b[0m | \u001b[0m 6.821   \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7984  \u001b[0m | \u001b[0m 1.94    \u001b[0m | \u001b[0m 746.3   \u001b[0m | \u001b[0m 22.54   \u001b[0m | \u001b[0m 0.837   \u001b[0m | \u001b[0m 73.15   \u001b[0m | \u001b[0m 6.762   \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7989  \u001b[0m | \u001b[0m 5.326   \u001b[0m | \u001b[0m 373.9   \u001b[0m | \u001b[0m 77.54   \u001b[0m | \u001b[0m 0.04056 \u001b[0m | \u001b[0m 47.68   \u001b[0m | \u001b[0m 1.969   \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7985  \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 541.1   \u001b[0m | \u001b[0m 87.25   \u001b[0m | \u001b[0m 0.1193  \u001b[0m | \u001b[0m 98.8    \u001b[0m | \u001b[0m 1.633   \u001b[0m |\n",
            "| \u001b[95m 26      \u001b[0m | \u001b[95m 0.956   \u001b[0m | \u001b[95m 9.0     \u001b[0m | \u001b[95m 200.0   \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 0.0     \u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9079  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 468.9   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 7.0     \u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.9324  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 7.0     \u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7986  \u001b[0m | \u001b[0m 0.1272  \u001b[0m | \u001b[0m 200.9   \u001b[0m | \u001b[0m 89.88   \u001b[0m | \u001b[0m 0.9396  \u001b[0m | \u001b[0m 16.07   \u001b[0m | \u001b[0m 0.5126  \u001b[0m |\n",
            "=================================================================================================\n"
          ]
        }
      ],
      "source": [
        "params_nn ={ 'neurons': (10, 100), 'activation':(0, 9), 'optimizer':(0,7), 'learning_rate':(0.01, 1), 'batch_size':(200,\n",
        "                                                                                                                    1000), 'epochs':(20, 100) }\n",
        "# Run Bayesian Optimization\n",
        "nn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=111)\n",
        "nn_bo.maximize(init_points=25, n_iter=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYKMrZ7EFpcm",
        "outputId": "8568671c-11e1-47f4-b488-5b362e14d59c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 200.0,\n",
              " 'epochs': 100.0,\n",
              " 'learning_rate': 0.01,\n",
              " 'neurons': 100.0,\n",
              " 'optimizer': 0.0}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_nn_ = nn_bo.max['params']\n",
        "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
        "               'elu', 'exponential', LeakyReLU,'relu']\n",
        "params_nn_['activation'] = activationL[round(params_nn_['activation'])]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}